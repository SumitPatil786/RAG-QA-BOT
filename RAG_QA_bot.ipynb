{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f5zT-xkDzDkD"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai pinecone tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aeKAKMamzilB"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pinecone\n",
        "import tiktoken\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e8LlPPNDzxMg"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "je_eMGJ3059K"
      },
      "outputs": [],
      "source": [
        "openai.api_key =\"\"\n",
        "PINECONE_API_KEY =\"\"\n",
        "PINECONE_ENV=\"us-east-1-aws\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JcRjTVoIAXJP"
      },
      "outputs": [],
      "source": [
        "from pinecone import Pinecone\n",
        "\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "index_name=\"business-qa-index\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9EFhTjX5An-D"
      },
      "outputs": [],
      "source": [
        "if not pc.has_index(index_name):\n",
        "    pc.create_index_for_model(\n",
        "        name=index_name,\n",
        "        cloud=\"aws\",\n",
        "        region=\"us-east-1\",\n",
        "        embed={\n",
        "            \"model\":\"llama-text-embed-v2\",\n",
        "            \"field_map\":{\"text\": \"chunk_text\"}\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DjZeYQkpBU0T"
      },
      "outputs": [],
      "source": [
        "index=pc.Index(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7HMsb_bfD4tk"
      },
      "outputs": [],
      "source": [
        "docs=[\n",
        "        \"Our refund policy allows customers to return products within 30 days.\",\n",
        "    \"We offer 24/7 customer support via email and live chat.\",\n",
        "    \"Our headquarters are located in San Francisco, California.\",\n",
        "    \"We specialize in cloud-based solutions for small businesses.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OeOPYvghEAav"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Use the client initialized with the correct API key from cell rT6J87lNE_WT\n",
        "# client = OpenAI(api_key=\"YOUR_OPENAI_API_KEY\") # This line is no longer needed\n",
        "\n",
        "def get_embeddings(texts):\n",
        "    response = client.embeddings.create(\n",
        "        input=texts,\n",
        "        model=\"text-embedding-3-small\"\n",
        "    )\n",
        "    return [e.embedding for e in response.data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rT6J87lNE_WT"
      },
      "outputs": [],
      "source": [
        "client = openai.OpenAI(api_key=\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "imblBY3BK3N-",
        "outputId": "f8a42427-497f-49c7-d6e6-5603800fcd6d"
      },
      "outputs": [
        {
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, emb) \u001b[38;5;28;01mfor\u001b[39;00m i, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(embeddings)]\n\u001b[0;32m      4\u001b[0m     index\u001b[38;5;241m.\u001b[39mupsert(vectors)\n\u001b[1;32m----> 6\u001b[0m upload_documents_to_pinecone(docs)\n",
            "Cell \u001b[1;32mIn[11], line 2\u001b[0m, in \u001b[0;36mupload_documents_to_pinecone\u001b[1;34m(docs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupload_documents_to_pinecone\u001b[39m(docs: List[\u001b[38;5;28mstr\u001b[39m]):\n\u001b[1;32m----> 2\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m get_embeddings(docs)\n\u001b[0;32m      3\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, emb) \u001b[38;5;28;01mfor\u001b[39;00m i, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(embeddings)]\n\u001b[0;32m      4\u001b[0m     index\u001b[38;5;241m.\u001b[39mupsert(vectors)\n",
            "Cell \u001b[1;32mIn[9], line 7\u001b[0m, in \u001b[0;36mget_embeddings\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embeddings\u001b[39m(texts):\n\u001b[1;32m----> 7\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m      9\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-3-small\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m     )\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [e\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdata]\n",
            "File \u001b[1;32mc:\\Users\\sumit\\anaconda3\\Lib\\site-packages\\openai\\resources\\embeddings.py:129\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    123\u001b[0m             embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    124\u001b[0m                 base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    125\u001b[0m             )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(params, embedding_create_params\u001b[38;5;241m.\u001b[39mEmbeddingCreateParams),\n\u001b[0;32m    132\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    133\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers,\n\u001b[0;32m    134\u001b[0m         extra_query\u001b[38;5;241m=\u001b[39mextra_query,\n\u001b[0;32m    135\u001b[0m         extra_body\u001b[38;5;241m=\u001b[39mextra_body,\n\u001b[0;32m    136\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    137\u001b[0m         post_parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[0;32m    138\u001b[0m     ),\n\u001b[0;32m    139\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mCreateEmbeddingResponse,\n\u001b[0;32m    140\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\sumit\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1249\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1237\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1245\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1246\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1247\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1248\u001b[0m     )\n\u001b[1;32m-> 1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
            "File \u001b[1;32mc:\\Users\\sumit\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1037\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1034\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1036\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1037\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ],
      "source": [
        "def upload_documents_to_pinecone(docs: List[str]):\n",
        "    embeddings = get_embeddings(docs)\n",
        "    vectors = [(f\"doc-{i}\", emb) for i, emb in enumerate(embeddings)]\n",
        "    index.upsert(vectors)\n",
        "\n",
        "upload_documents_to_pinecone(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xcCF_CG-F6cO"
      },
      "outputs": [],
      "source": [
        "def retrieve_context(query: str, top_k: int = 3) -> str:\n",
        "    query_embedding = get_embeddings([query])[0]\n",
        "    result = index.query(vector=query_embedding, top_k=top_k, include_metadata=True)\n",
        "    return \"\\n\".join([match['metadata']['text'] for match in result['matches']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MIDP4iFINcz1"
      },
      "outputs": [],
      "source": [
        "def generate_answer(query: str, context: str) -> str:\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful assistant. Use the following business knowledge to answer the question.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "Answer:\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.2\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0ZmDWCE5Nir_"
      },
      "outputs": [],
      "source": [
        "def rag_qa(query: str):\n",
        "    context = retrieve_context(query)\n",
        "    answer = generate_answer(query, context)\n",
        "    display(Markdown(f\"###  Question:\\n{query}\"))\n",
        "    display(Markdown(f\"###  Retrieved Context:\\n{context}\"))\n",
        "    display(Markdown(f\"###  Answer:\\n{answer}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "iIrLjNAfNz1z",
        "outputId": "b5ded03b-777f-4a8f-80b4-c6655e0016ed"
      },
      "outputs": [
        {
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Example\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m rag_qa(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhere is your company headquarters?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[14], line 2\u001b[0m, in \u001b[0;36mrag_qa\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrag_qa\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     context \u001b[38;5;241m=\u001b[39m retrieve_context(query)\n\u001b[0;32m      3\u001b[0m     answer \u001b[38;5;241m=\u001b[39m generate_answer(query, context)\n\u001b[0;32m      4\u001b[0m     display(Markdown(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m###  Question:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
            "Cell \u001b[1;32mIn[12], line 2\u001b[0m, in \u001b[0;36mretrieve_context\u001b[1;34m(query, top_k)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mretrieve_context\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m, top_k: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m get_embeddings([query])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m     result \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39mquery(vector\u001b[38;5;241m=\u001b[39mquery_embedding, top_k\u001b[38;5;241m=\u001b[39mtop_k, include_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([match[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatches\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
            "Cell \u001b[1;32mIn[9], line 7\u001b[0m, in \u001b[0;36mget_embeddings\u001b[1;34m(texts)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_embeddings\u001b[39m(texts):\n\u001b[1;32m----> 7\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[0;32m      9\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-3-small\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m     )\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [e\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdata]\n",
            "File \u001b[1;32mc:\\Users\\sumit\\anaconda3\\Lib\\site-packages\\openai\\resources\\embeddings.py:129\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    123\u001b[0m             embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    124\u001b[0m                 base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    125\u001b[0m             )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    131\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(params, embedding_create_params\u001b[38;5;241m.\u001b[39mEmbeddingCreateParams),\n\u001b[0;32m    132\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    133\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers,\n\u001b[0;32m    134\u001b[0m         extra_query\u001b[38;5;241m=\u001b[39mextra_query,\n\u001b[0;32m    135\u001b[0m         extra_body\u001b[38;5;241m=\u001b[39mextra_body,\n\u001b[0;32m    136\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    137\u001b[0m         post_parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[0;32m    138\u001b[0m     ),\n\u001b[0;32m    139\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mCreateEmbeddingResponse,\n\u001b[0;32m    140\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\sumit\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1249\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1237\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1245\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1246\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1247\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1248\u001b[0m     )\n\u001b[1;32m-> 1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
            "File \u001b[1;32mc:\\Users\\sumit\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1037\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1034\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1036\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1037\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ],
      "source": [
        "#Example\n",
        "rag_qa(\"Where is your company headquarters?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoYJ9gWvN47T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
